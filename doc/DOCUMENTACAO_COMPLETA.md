# ğŸ“š DocumentaÃ§Ã£o - Sistema de AutomaÃ§Ã£o Azure DevOps

## ğŸ¯ VisÃ£o Geral

Este sistema automatiza a criaÃ§Ã£o de work items no Azure DevOps baseado em tickets do sistema Fusion, usando Apache Airflow para orquestraÃ§Ã£o e Python para integraÃ§Ã£o com APIs.

## ğŸ“‹ Ãndice

1. [Como Funciona o Sistema](#como-funciona)
2. [Arquitetura do Projeto](#arquitetura)
3. [Componentes Principais](#componentes)
4. [ConfiguraÃ§Ã£o e Uso](#configuracao)
5. [Fluxo de ExecuÃ§Ã£o](#fluxo)
6. [ResoluÃ§Ã£o de Problemas](#problemas)
7. [Desenvolvimento](#desenvolvimento)

---

## ğŸ”„ Como Funciona o Sistema {#como-funciona}

### O Problema que Resolve

**Antes:** Tickets criados no sistema Fusion precisavam ser manualmente transferidos para o Azure DevOps como work items.

**Agora:** O sistema automaticamente:
1. ğŸ” Busca tickets pendentes no Fusion (SQL Server)
2. âœ… Verifica se jÃ¡ existem cards no Azure DevOps
3. ğŸ¯ Cria work items apenas para tickets novos
4. ğŸ“§ Envia notificaÃ§Ã£o com resultados

### Fluxo Simplificado

```
ğŸ“Š Fusion (SQL)  â†’  ğŸ”„ Airflow  â†’  ğŸ“‹ Azure DevOps
    Tickets           Processa      Work Items
```

---

## ğŸ—ï¸ Arquitetura do Projeto {#arquitetura}

### Estrutura de Pastas

```
ğŸ“ azure-devops/
â”œâ”€â”€ ğŸ³ docker-compose.yml        # Ambiente Airflow
â”œâ”€â”€ ğŸ“‹ dags/                     # DAGs do Airflow
â”‚   â”œâ”€â”€ __init__.py              # Config Python path
â”‚   â””â”€â”€ azure_devops_production_dag.py  # DAG principal
â”œâ”€â”€ ğŸ”§ src/azure_devops_integration/    # CÃ³digo de produÃ§Ã£o
â”‚   â”œâ”€â”€ __init__.py              # Exports do pacote
â”‚   â”œâ”€â”€ client.py                # Cliente Azure DevOps
â”‚   â””â”€â”€ config.py                # ConfiguraÃ§Ãµes
â”œâ”€â”€ ğŸ§ª test_with_mocks.py        # Testes com dados falsos
â”œâ”€â”€ ğŸ” .env                      # Credenciais (seguro)
â”œâ”€â”€ ğŸ“š doc/                      # DocumentaÃ§Ã£o
â””â”€â”€ ğŸ“ requirements.txt          # DependÃªncias Python
```

### Tecnologias Utilizadas

- **ğŸ Python 3.13:** Linguagem principal
- **ğŸŒŠ Apache Airflow 2.8.1:** OrquestraÃ§Ã£o de workflows
- **ğŸ³ Docker:** Ambiente isolado e reproduzÃ­vel
- **ğŸ˜ PostgreSQL:** Banco do Airflow
- **â˜ï¸ Azure DevOps API 7.1:** IntegraÃ§Ã£o com Azure
- **ğŸ“Š SQL Server:** Fonte dos dados (Fusion)

---

## ğŸ§© Componentes Principais {#componentes}

### 1. ğŸ“‹ DAG Principal (`azure_devops_production_dag.py`)

**O que faz:** Orquestra todo o processo de automaÃ§Ã£o

**Tasks (etapas):**
1. **`get_pending_tickets`** - Busca tickets no Fusion
2. **`check_existing_cards`** - Verifica duplicatas 
3. **`create_azure_devops_cards`** - Cria work items
4. **`send_notification`** - Envia notificaÃ§Ã£o

**Exemplo de execuÃ§Ã£o:**
```python
# O DAG roda automaticamente a cada 6 horas
# Ou pode ser executado manualmente no Airflow UI
```

### 2. ğŸ”§ Cliente Azure DevOps (`client.py`)

**O que faz:** Gerencia toda comunicaÃ§Ã£o com Azure DevOps

**Principais mÃ©todos:**
```python
# Testa se consegue conectar
client.test_connection()

# Cria um work item individual  
client.create_work_item_from_ticket(ticket_data)

# Cria mÃºltiplos work items
client.create_work_items_batch(tickets_list)

# Valida dados antes de criar
client.validate_ticket(ticket_data)
```

### 3. âš™ï¸ ConfiguraÃ§Ãµes (`config.py`)

**O que faz:** Define mapeamentos e configuraÃ§Ãµes

**Mapeamentos importantes:**
```python
# Categoria â†’ Tipo de Work Item
'Desenvolvimento' â†’ 'Product backlog item'
'Bug' â†’ 'Bug'
'Feature' â†’ 'User Story'

# Prioridade â†’ NÃºmero
'CrÃ­tica' â†’ 1
'Alta' â†’ 2  
'Normal' â†’ 3
'Baixa' â†’ 4
```

---

## âš™ï¸ ConfiguraÃ§Ã£o e Uso {#configuracao}

### PrÃ©-requisitos

1. **Docker Desktop** instalado
2. **Credenciais Azure DevOps:**
   - OrganizaÃ§Ã£o (ex: `welbertsoares`)
   - Projeto (ex: `cards-kanban-welbert-teste`)
   - Personal Access Token (PAT)

### Primeira ExecuÃ§Ã£o

1. **Inicie o ambiente:**
```bash
docker-compose up -d
```

2. **Configure credenciais:**
```bash
# As credenciais jÃ¡ estÃ£o no arquivo .env
# Elas foram configuradas automaticamente no Airflow
```

3. **Acesse o Airflow:**
- URL: http://localhost:8080
- Login: admin / admin

4. **Ative o DAG:**
- Encontre `azure_devops_card_creation`
- Clique no toggle para ativar

### ExecuÃ§Ã£o Manual

**Via Airflow UI:**
1. VÃ¡ para http://localhost:8080
2. Clique em `azure_devops_card_creation`
3. Clique em "Trigger DAG"

**Via comando:**
```bash
docker-compose exec airflow-scheduler airflow dags trigger azure_devops_card_creation
```

### Monitoramento

**Logs em tempo real:**
```bash
docker-compose logs -f airflow-scheduler
```

**Status das execuÃ§Ãµes:**
- Acesse o Airflow UI
- VÃ¡ em "DAGs" â†’ "azure_devops_card_creation"
- Veja histÃ³rico de execuÃ§Ãµes

---

## ğŸ”„ Fluxo de ExecuÃ§Ã£o Detalhado {#fluxo}

### Etapa 1: Buscar Tickets (`get_pending_tickets`)

**O que acontece:**
```python
# 1. Conecta no SQL Server do Fusion
# 2. Executa query para buscar tickets pendentes
# 3. Filtra apenas tickets nÃ£o processados
# 4. Passa dados para prÃ³xima etapa
```

**Atualmente:** Usa dados mockados (teste)
**Em produÃ§Ã£o:** ConectarÃ¡ ao SQL Server real

### Etapa 2: Verificar Existentes (`check_existing_cards`)

**O que acontece:**
```python
# 1. Recebe lista de tickets da etapa anterior
# 2. Para cada ticket, verifica se jÃ¡ existe work item
# 3. Filtra apenas tickets realmente novos
# 4. Testa conexÃ£o com Azure DevOps
```

### Etapa 3: Criar Cards (`create_azure_devops_cards`)

**O que acontece:**
```python
# 1. Recebe tickets novos da etapa anterior
# 2. Para cada ticket:
#    - Valida dados obrigatÃ³rios
#    - Mapeia categoria â†’ tipo de work item
#    - Define prioridade e estado inicial
#    - Cria work item via API
# 3. Coleta resultados (sucessos e falhas)
```

### Etapa 4: Notificar (`send_notification`)

**O que acontece:**
```python
# 1. Coleta resultados das etapas anteriores
# 2. Monta relatÃ³rio com estatÃ­sticas
# 3. Envia notificaÃ§Ã£o (atualmente apenas log)
# 4. Em produÃ§Ã£o: enviarÃ¡ email/webhook
```

---

## ğŸ”§ ResoluÃ§Ã£o de Problemas {#problemas}

### Problema: DAG nÃ£o aparece no Airflow

**SoluÃ§Ã£o:**
```bash
# Verificar erros de importaÃ§Ã£o
docker-compose exec airflow-scheduler airflow dags list-import-errors

# Se houver erros, verificar logs
docker-compose logs airflow-scheduler
```

### Problema: Erro de conexÃ£o Azure DevOps

**VerificaÃ§Ãµes:**
1. **Token vÃ¡lido:** Verifique se o PAT nÃ£o expirou
2. **PermissÃµes:** Token precisa de permissÃ£o para Work Items
3. **OrganizaÃ§Ã£o/Projeto:** Nomes devem estar corretos

**Teste manual:**
```bash
docker-compose exec airflow-scheduler python -c "
import sys
sys.path.insert(0, '/opt/airflow/src')
from azure_devops_integration.client import create_azure_devops_client
from airflow.models import Variable

org = Variable.get('azure_devops_organization')
project = Variable.get('azure_devops_project')  
pat = Variable.get('azure_devops_pat')

client = create_azure_devops_client(org, project, pat)
print('ConexÃ£o:', 'OK' if client.test_connection() else 'ERRO')
"
```

### Problema: Tasks falhando

**InvestigaÃ§Ã£o:**
1. **Ver logs especÃ­ficos:** No Airflow UI, clique na task que falhou
2. **Verificar dados:** Confirme se os dados estÃ£o no formato esperado
3. **Testar isoladamente:** Use `test_with_mocks.py` para testar componentes

### Problema: Credenciais perdidas

**SoluÃ§Ã£o:**
```bash
# Restaurar do arquivo .env
source .env

# Reconfigurar no Airflow
docker-compose exec airflow-scheduler airflow variables set azure_devops_organization "sua-org"
docker-compose exec airflow-scheduler airflow variables set azure_devops_project "seu-projeto"
docker-compose exec airflow-scheduler airflow variables set azure_devops_pat "seu-token"
```

---

## ğŸ’» Desenvolvimento {#desenvolvimento}

### Testando Localmente

**Usar dados mockados:**
```bash
python test_with_mocks.py
```

**Testar apenas o cliente:**
```python
from src.azure_devops_integration.client import create_azure_devops_client

client = create_azure_devops_client("org", "projeto", "token")
print(client.test_connection())
```

### Adicionando Novas Funcionalidades

1. **Modificar configuraÃ§Ãµes:** Edite `src/azure_devops_integration/config.py`
2. **Adicionar mÃ©todos:** Edite `src/azure_devops_integration/client.py`
3. **Modificar workflow:** Edite `dags/azure_devops_production_dag.py`
4. **Testar:** Use `test_with_mocks.py`

### Estrutura de um Ticket

```python
ticket = {
    'id': 'GITI.123456/2025',           # ObrigatÃ³rio
    'titulo': 'TÃ­tulo do chamado',       # ObrigatÃ³rio  
    'descricao': 'DescriÃ§Ã£o detalhada',  # Opcional
    'categoria': 'Desenvolvimento',      # Mapeia para tipo
    'prioridade': 'Alta',               # Mapeia para nÃºmero
    'solicitante': 'Nome da Pessoa',    # Informativo
    'status': 'Pendente'                # Informativo
}
```

### Logs Importantes

**Cliente inicializando:**
```
Cliente inicializado para welbertsoares/cards-kanban-welbert-teste
```

**ConexÃ£o estabelecida:**
```
ConexÃ£o estabelecida! Projetos encontrados: 2
```

**Work item criado:**
```
Work item criado: ID 51
URL: https://dev.azure.com/.../_workitems/edit/51
```

---

## ğŸ“Š MÃ©tricas e Monitoramento

### Como Acompanhar Performance

**No Airflow UI:**
- Tempo de execuÃ§Ã£o de cada task
- Taxa de sucesso/falha
- HistÃ³rico de execuÃ§Ãµes

**Logs importantes:**
- Quantos tickets foram processados
- Quantos work items foram criados
- Quais falharam e por quÃª

### ConfiguraÃ§Ãµes de ExecuÃ§Ã£o

**Agendamento atual:** A cada 6 horas
**Timeout por task:** 30 segundos
**Tentativas em caso de falha:** 2
**Delay entre tentativas:** 5 minutos

---

## ğŸš€ PrÃ³ximos Passos

### Para ProduÃ§Ã£o Completa:

1. **Conectar SQL Server real:**
   - Configurar string de conexÃ£o
   - Implementar queries especÃ­ficas do Fusion
   - Adicionar tratamento de erros de BD

2. **Melhorar notificaÃ§Ãµes:**
   - Configurar envio de email
   - Implementar webhooks
   - Dashboard de mÃ©tricas

3. **OtimizaÃ§Ãµes:**
   - Cache de verificaÃ§Ãµes
   - Processamento em paralelo
   - Retry inteligente

---

## ğŸ“ Suporte

**Para dÃºvidas:**
1. Consulte esta documentaÃ§Ã£o
2. Verifique logs no Airflow UI
3. Teste com `test_with_mocks.py`
4. Verifique o arquivo `CREDENTIALS_GUIDE.md`

**Arquivos importantes:**
- `.env` - Backup das credenciais
- `docker-compose.yml` - ConfiguraÃ§Ã£o do ambiente
- `logs/` - Logs histÃ³ricos do Airflow
